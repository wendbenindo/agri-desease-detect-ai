#!/usr/bin/env python3
"""
"""

import os
import sys
import json
import argparse
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.imagenet_utils import preprocess_input
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image, ImageEnhance, ImageFilter
import cv2
from pathlib import Path
import warnings
import logging
from datetime import datetime
import pandas as pd

# Configuration des warnings
warnings.filterwarnings('ignore')

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('prediction.log'),
        logging.StreamHandler()
    ]
)

class PlantDiseasePredictor:
    """
    Classe compl√®te pour la pr√©diction optimis√©e de maladies de plantes
    avec pr√©processing avanc√© et analyse d√©taill√©e
    """
    
    def __init__(self, model_path=None, metadata_path=None, confidence_threshold=0.5):
        """
        Initialise le pr√©dicteur avec gestion d'erreurs robuste
        """
        self.model_path = model_path or self._find_model_path()
        self.metadata_path = metadata_path or self._find_metadata_path()
        self.confidence_threshold = confidence_threshold
        
        # Chargement des composants
        self.model = None
        self.class_names = None
        self.class_indices = None
        self.img_size = (224, 224)
        self.model_architecture = None
        
        # Initialisation
        self._load_model_and_metadata()
        self._setup_gpu()
        
        logging.info("üöÄ Pr√©dicteur initialis√© avec succ√®s")
    
    def _find_model_path(self):
        """Trouve automatiquement le chemin du mod√®le"""
        possible_paths = [
            '../model/plant_disease_model_optimized.h5',
            './model/plant_disease_model_optimized.h5',
            'model/plant_disease_model_optimized.h5'
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
        
        raise FileNotFoundError("‚ùå Mod√®le non trouv√©. V√©rifiez le chemin.")
    
    def _find_metadata_path(self):
        """Trouve automatiquement le chemin des m√©tadonn√©es"""
        possible_paths = [
            '../model/model_metadata.json',
            './model/model_metadata.json',
            'model/model_metadata.json'
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
        
        raise FileNotFoundError("‚ùå M√©tadonn√©es non trouv√©es. V√©rifiez le chemin.")
    
    def _setup_gpu(self):
        """Configuration GPU optimis√©e"""
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            try:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                logging.info(f"‚úÖ GPU configur√©: {len(gpus)} GPU(s)")
            except RuntimeError as e:
                logging.warning(f"‚ö†Ô∏è Erreur GPU: {e}")
        else:
            logging.info("üíª Utilisation du CPU")
    
    def _load_model_and_metadata(self):
        """Charge le mod√®le et les m√©tadonn√©es avec gestion d'erreurs"""
        try:
            # Chargement du mod√®le
            logging.info(f"üì• Chargement du mod√®le: {self.model_path}")
            self.model = load_model(self.model_path)
            
            # Chargement des m√©tadonn√©es
            logging.info(f"üì• Chargement des m√©tadonn√©es: {self.metadata_path}")
            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # Extraction des informations
            self.class_indices = metadata['class_indices']
            self.class_names = [name for name, idx in 
                              sorted(self.class_indices.items(), key=lambda x: x[1])]
            self.img_size = tuple(metadata.get('img_size', (224, 224)))
            self.model_architecture = metadata.get('model_architecture', 'unknown')
            
            logging.info(f"‚úÖ Mod√®le charg√©: {len(self.class_names)} classes")
            logging.info(f"üèóÔ∏è Architecture: {self.model_architecture}")
            
        except Exception as e:
            logging.error(f"‚ùå Erreur lors du chargement: {e}")
            raise
    
    def _validate_image_path(self, img_path):
        """Valide le chemin de l'image"""
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"‚ùå Image non trouv√©e: {img_path}")
        
        valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        if not any(img_path.lower().endswith(ext) for ext in valid_extensions):
            raise ValueError(f"‚ùå Format d'image non support√©: {img_path}")
        
        return True
    
    def _advanced_preprocessing(self, img_path):
        """
        Pr√©processing avanc√© avec am√©lioration d'image
        """
        try:
            # Chargement de l'image
            img = Image.open(img_path).convert('RGB')
            
            # Am√©lioration de l'image
            img = self._enhance_image(img)
            
            # Redimensionnement intelligent
            img = self._smart_resize(img)
            
            # Conversion en array numpy
            img_array = np.array(img, dtype=np.float32)
            
            # Normalisation selon l'architecture du mod√®le
            if self.model_architecture in ['mobilenetv2', 'efficientnetb0']:
                img_array = (img_array / 127.5) - 1.0  # Normalisation [-1, 1]
            else:
                img_array = img_array / 255.0  # Normalisation [0, 1]
            
            # Ajout de la dimension batch
            img_array = np.expand_dims(img_array, axis=0)
            
            return img_array, img
            
        except Exception as e:
            logging.error(f"‚ùå Erreur pr√©processing: {e}")
            raise
    
    def _enhance_image(self, img):
        """Am√©liore la qualit√© de l'image"""
        try:
            # Am√©lioration du contraste
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(1.2)
            
            # Am√©lioration de la nettet√©
            enhancer = ImageEnhance.Sharpness(img)
            img = enhancer.enhance(1.1)
            
            # Filtre de r√©duction du bruit
            img = img.filter(ImageFilter.SMOOTH_MORE)
            
            return img
            
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Erreur am√©lioration image: {e}")
            return img
    
    def _smart_resize(self, img):
        """Redimensionnement intelligent pr√©servant l'aspect ratio"""
        try:
            # Calculer le ratio
            w, h = img.size
            target_w, target_h = self.img_size
            
            # Redimensionner en gardant le ratio
            if w/h > target_w/target_h:
                new_w = target_w
                new_h = int(h * target_w / w)
            else:
                new_h = target_h
                new_w = int(w * target_h / h)
            
            img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            
            # Padding pour atteindre la taille cible
            new_img = Image.new('RGB', (target_w, target_h), (0, 0, 0))
            paste_x = (target_w - new_w) // 2
            paste_y = (target_h - new_h) // 2
            new_img.paste(img, (paste_x, paste_y))
            
            return new_img
            
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Erreur redimensionnement: {e}")
            return img.resize(self.img_size, Image.Resampling.LANCZOS)
    
    def _analyze_predictions(self, predictions, top_k=5):
        """Analyse avanc√©e des pr√©dictions"""
        try:
            # Tri des pr√©dictions
            sorted_indices = predictions.argsort()[::-1]
            
            # Calcul des statistiques
            max_confidence = np.max(predictions)
            entropy = -np.sum(predictions * np.log(predictions + 1e-10))
            
            # Classification de la certitude
            if max_confidence > 0.9:
                certainty = "Tr√®s √©lev√©e"
            elif max_confidence > 0.7:
                certainty = "√âlev√©e"
            elif max_confidence > 0.5:
                certainty = "Mod√©r√©e"
            else:
                certainty = "Faible"
            
            # R√©sultats Top-K
            results = []
            for i in range(min(top_k, len(sorted_indices))):
                idx = sorted_indices[i]
                confidence = predictions[idx]
                
                results.append({
                    'class': self.class_names[idx],
                    'confidence': float(confidence),
                    'percentage': f"{confidence * 100:.2f}%"
                })
            
            analysis = {
                'top_predictions': results,
                'max_confidence': float(max_confidence),
                'entropy': float(entropy),
                'certainty_level': certainty,
                'is_reliable': max_confidence > self.confidence_threshold
            }
            
            return analysis
            
        except Exception as e:
            logging.error(f"‚ùå Erreur analyse: {e}")
            raise
    
    def predict_single_image(self, img_path, show_details=True, save_results=False):
        """
        Pr√©diction compl√®te pour une image unique
        """
        try:
            # Validation
            self._validate_image_path(img_path)
            
            logging.info(f"üîç Analyse de l'image: {os.path.basename(img_path)}")
            
            # Pr√©processing
            img_array, original_img = self._advanced_preprocessing(img_path)
            
            # Pr√©diction
            predictions = self.model.predict(img_array, verbose=0)[0]
            
            # Analyse des r√©sultats
            analysis = self._analyze_predictions(predictions)
            
            # Affichage des r√©sultats
            if show_details:
                self._display_results(img_path, analysis, original_img)
            
            # Sauvegarde des r√©sultats
            if save_results:
                self._save_results(img_path, analysis)
            
            return analysis
            
        except Exception as e:
            logging.error(f"‚ùå Erreur pr√©diction: {e}")
            raise
    
    def _display_results(self, img_path, analysis, original_img):
        """Affiche les r√©sultats de mani√®re format√©e"""
        print("\n" + "="*60)
        print(f"üñºÔ∏è  IMAGE ANALYS√âE: {os.path.basename(img_path)}")
        print("="*60)
        
        # Pr√©diction principale
        top_pred = analysis['top_predictions'][0]
        print(f"üéØ PR√âDICTION PRINCIPALE:")
        print(f"   ‚Ä¢ Maladie: {top_pred['class']}")
        print(f"   ‚Ä¢ Confiance: {top_pred['percentage']}")
        print(f"   ‚Ä¢ Niveau de certitude: {analysis['certainty_level']}")
        
        # Fiabilit√©
        reliability = "‚úÖ Fiable" if analysis['is_reliable'] else "‚ö†Ô∏è Peu fiable"
        print(f"   ‚Ä¢ Fiabilit√©: {reliability}")
        
        # Top 3 pr√©dictions
        print(f"\nüîç TOP 3 PR√âDICTIONS:")
        for i, pred in enumerate(analysis['top_predictions'][:3], 1):
            print(f"   {i}. {pred['class']} ({pred['percentage']})")
        
        # Statistiques avanc√©es
        print(f"\nüìä STATISTIQUES:")
        print(f"   ‚Ä¢ Entropie: {analysis['entropy']:.3f}")
        print(f"   ‚Ä¢ Confiance max: {analysis['max_confidence']:.3f}")
        
        # Recommandations
        self._display_recommendations(analysis)
        
        print("="*60)
    
    def _display_recommendations(self, analysis):
        """Affiche des recommandations bas√©es sur l'analyse"""
        print(f"\nüí° RECOMMANDATIONS:")
        
        if analysis['max_confidence'] > 0.9:
            print("   ‚Ä¢ Pr√©diction tr√®s fiable, vous pouvez avoir confiance")
        elif analysis['max_confidence'] > 0.7:
            print("   ‚Ä¢ Pr√©diction fiable, mais v√©rifiez avec d'autres sources")
        elif analysis['max_confidence'] > 0.5:
            print("   ‚Ä¢ Pr√©diction incertaine, consultez un expert")
        else:
            print("   ‚Ä¢ Pr√©diction peu fiable, image de mauvaise qualit√© ?")
            print("   ‚Ä¢ Essayez avec une image plus nette ou mieux √©clair√©e")
    
    def _save_results(self, img_path, analysis):
        """Sauvegarde les r√©sultats dans un fichier JSON"""
        try:
            results_dir = Path("results")
            results_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"prediction_{timestamp}.json"
            
            result_data = {
                'timestamp': datetime.now().isoformat(),
                'image_path': img_path,
                'image_name': os.path.basename(img_path),
                'model_architecture': self.model_architecture,
                'analysis': analysis
            }
            
            with open(results_dir / filename, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, indent=2, ensure_ascii=False)
            
            logging.info(f"üíæ R√©sultats sauvegard√©s: {filename}")
            
        except Exception as e:
            logging.error(f"‚ùå Erreur sauvegarde: {e}")
    
    def predict_batch(self, image_folder, output_csv=None):
        """
        Pr√©diction par lot pour un dossier d'images
        """
        try:
            image_folder = Path(image_folder)
            if not image_folder.exists():
                raise FileNotFoundError(f"‚ùå Dossier non trouv√©: {image_folder}")
            
            # Extensions support√©es
            valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
            image_files = []
            
            for ext in valid_extensions:
                image_files.extend(image_folder.glob(f"*{ext}"))
                image_files.extend(image_folder.glob(f"*{ext.upper()}"))
            
            if not image_files:
                raise ValueError("‚ùå Aucune image trouv√©e dans le dossier")
            
            logging.info(f"üîç Traitement par lot: {len(image_files)} images")
            
            # Traitement des images
            results = []
            for i, img_path in enumerate(image_files, 1):
                try:
                    print(f"üì∏ Traitement {i}/{len(image_files)}: {img_path.name}")
                    
                    analysis = self.predict_single_image(
                        str(img_path), 
                        show_details=False, 
                        save_results=False
                    )
                    
                    # Pr√©parer les donn√©es pour CSV
                    top_pred = analysis['top_predictions'][0]
                    results.append({
                        'image_name': img_path.name,
                        'predicted_class': top_pred['class'],
                        'confidence': top_pred['confidence'],
                        'percentage': top_pred['percentage'],
                        'certainty_level': analysis['certainty_level'],
                        'is_reliable': analysis['is_reliable']
                    })
                    
                except Exception as e:
                    logging.error(f"‚ùå Erreur image {img_path.name}: {e}")
                    results.append({
                        'image_name': img_path.name,
                        'predicted_class': 'ERROR',
                        'confidence': 0.0,
                        'percentage': '0.00%',
                        'certainty_level': 'Error',
                        'is_reliable': False
                    })
            
            # Sauvegarde CSV
            if output_csv:
                df = pd.DataFrame(results)
                df.to_csv(output_csv, index=False, encoding='utf-8')
                logging.info(f"üìä R√©sultats sauvegard√©s: {output_csv}")
            
            return results
            
        except Exception as e:
            logging.error(f"‚ùå Erreur traitement par lot: {e}")
            raise
    
    def visualize_prediction(self, img_path, save_plot=False):
        """
        Visualise la pr√©diction avec graphiques
        """
        try:
            # Pr√©diction
            analysis = self.predict_single_image(img_path, show_details=False)
            
            # Cr√©ation du graphique
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # Image originale
            img = Image.open(img_path)
            ax1.imshow(img)
            ax1.set_title(f"Image: {os.path.basename(img_path)}")
            ax1.axis('off')
            
            # Graphique des pr√©dictions
            top_5 = analysis['top_predictions'][:5]
            classes = [pred['class'] for pred in top_5]
            confidences = [pred['confidence'] for pred in top_5]
            
            bars = ax2.barh(classes, confidences)
            ax2.set_xlabel('Confiance')
            ax2.set_title('Top 5 Pr√©dictions')
            ax2.set_xlim(0, 1)
            
            # Couleurs des barres
            for i, bar in enumerate(bars):
                if i == 0:
                    bar.set_color('green')
                else:
                    bar.set_color('lightblue')
            
            # Ajout des pourcentages
            for i, (class_name, confidence) in enumerate(zip(classes, confidences)):
                ax2.text(confidence + 0.01, i, f'{confidence*100:.1f}%', 
                        va='center', fontweight='bold')
            
            plt.tight_layout()
            
            if save_plot:
                plot_path = f"prediction_plot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                logging.info(f"üìä Graphique sauvegard√©: {plot_path}")
            
            plt.show()
            
        except Exception as e:
            logging.error(f"‚ùå Erreur visualisation: {e}")
            raise

def main():
    """Fonction principale avec interface CLI"""
    parser = argparse.ArgumentParser(description="Pr√©diction de maladies de plantes")
    parser.add_argument("image_path", help="Chemin vers l'image √† analyser")
    parser.add_argument("--model", help="Chemin vers le mod√®le .h5")
    parser.add_argument("--metadata", help="Chemin vers les m√©tadonn√©es JSON")
    parser.add_argument("--threshold", type=float, default=0.5, 
                       help="Seuil de confiance (d√©faut: 0.5)")
    parser.add_argument("--save", action="store_true", 
                       help="Sauvegarder les r√©sultats")
    parser.add_argument("--visualize", action="store_true",
                       help="Afficher la visualisation")
    parser.add_argument("--batch", action="store_true",
                       help="Traitement par lot (dossier d'images)")
    parser.add_argument("--output", help="Fichier CSV de sortie pour le batch")
    
    args = parser.parse_args()
    
    try:
        # Initialisation du pr√©dicteur
        predictor = PlantDiseasePredictor(
            model_path=args.model,
            metadata_path=args.metadata,
            confidence_threshold=args.threshold
        )
        
        if args.batch:
            # Traitement par lot
            results = predictor.predict_batch(args.image_path, args.output)
            print(f"\n‚úÖ Traitement termin√©: {len(results)} images")
        else:
            # Pr√©diction simple
            analysis = predictor.predict_single_image(
                args.image_path, 
                show_details=True, 
                save_results=args.save
            )
            
            if args.visualize:
                predictor.visualize_prediction(args.image_path, save_plot=args.save)
    
    except Exception as e:
        logging.error(f"‚ùå Erreur critique: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()